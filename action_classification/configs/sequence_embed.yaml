# Sequence embedding training config (LSTM/GRU over code indices)

seed: 0

# If provided, overrides dataset-inferred size. Effective embedding table will be codebook_size + 1
# because index 0 is reserved for PAD after an +1 offset of true codes.
codebook_size: 2048

sequence:
# 如果code indices (latent action sequences) 序列长度变为了 5*16 (5个窗口)，则 max_len 需要改为 80
# 来自YoLo的50帧片段，每个无重叠窗口16帧，所以是32
  max_len: auto
  pad_id: 0

model:
  d_model: 128
  rnn_type: lstm   # lstm | gru
  num_layers: 2
  dropout: 0.1
  bidirectional: true

objective:
  task: ntp        # ntp | (future: mlm)
  mlm_rate: 0.15   # reserved for future use

train:
  batch_size: 256
  epochs: 60
  lr: 1.0e-3
  weight_decay: 1.0e-4
  clip_grad_norm: 1.0
  val_split: 0.1           # stratified split
  balance_sampler: true    # class-balanced sampler for training
  num_workers: 2
  pin_memory: true
  patience: 8
  min_delta: 5.0e-4

export:
  out_dir: action_classification/analysis/seq_embed
  l2_normalize: true
